# ğŸš€ GuÃ­a de EjecuciÃ³n - Bot Multiagente LangGraph

Esta guÃ­a te llevarÃ¡ paso a paso para ejecutar el bot multiagente con Qwen3:8B local.

---

## ğŸ“‹ Prerrequisitos

- **Python 3.8+**
- **Ollama** instalado y corriendo
- **Git** (para clonar el repositorio)

---

## ğŸ› ï¸ InstalaciÃ³n de Ollama

### macOS/Linux:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Windows:
Descargar desde: https://ollama.ai/download

### Verificar instalaciÃ³n:
```bash
ollama --version
```

---

## ğŸš€ Pasos para ejecutar

### **1ï¸âƒ£ Preparar el entorno**

```bash
# Navegar al directorio del proyecto
cd langgraph

# Crear entorno virtual
# mv .venv .venv-old
# python -m venv .venv
python3.13 -m venv .venv


# Activar entorno virtual
source .venv/bin/activate  # macOS/Linux
# o
.venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### **2ï¸âƒ£ Configurar variables de entorno**

```bash
# Copiar archivo de ejemplo
cp .env.example .env

# El archivo .env ya estÃ¡ configurado para usar Qwen3:8B local
# No necesitas modificar nada si usas la configuraciÃ³n por defecto
```

### **3ï¸âƒ£ Verificar Ollama y modelo**

```bash
# Iniciar Ollama (si no estÃ¡ corriendo)
ollama serve

# En otra terminal, verificar modelos disponibles
ollama list

brew services start ollama

brew services stop ollama

# Si no tienes qwen3:8b, descargarlo (puede tardar varios minutos)
ollama pull qwen3:8b

# Verificar que la API de Ollama responde
curl http://localhost:11434/api/tags
```

### **4ï¸âƒ£ Ejecutar la API FastAPI (Terminal 1)**

```bash
# Desde la carpeta del proyecto (con .venv activado)
python -m uvicorn src.app:app --reload --port 8000
```

**âœ… DeberÃ­as ver:**
```
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete.
```

**ğŸŒ API disponible en:** http://localhost:8000

### **5ï¸âƒ£ Ejecutar interfaz Streamlit (Terminal 2)**

```bash
# En otra terminal, misma carpeta (con .venv activado)
streamlit run streamlit_app.py
```

**âœ… Se abrirÃ¡ automÃ¡ticamente en:** http://localhost:8501

---

## ğŸ§ª Pruebas sugeridas

Una vez que ambos servicios estÃ©n corriendo, prueba estos ejemplos:

1. **ğŸ’¬ Chat bÃ¡sico:**
   > "Hola, Â¿cÃ³mo estÃ¡s?"

2. **ğŸŒ¤ï¸ Consulta del clima:**
   > "Â¿CÃ³mo estÃ¡ el clima en Madrid hoy?"

3. **ğŸ–¼ï¸ GeneraciÃ³n de imÃ¡genes:**
   > "Genera una imagen de un gato minimalista"

---

## ğŸ”§ SoluciÃ³n de problemas

### **Ollama no responde:**
```bash
# Verificar si Ollama estÃ¡ corriendo
ps aux | grep ollama

# Si no estÃ¡ corriendo, iniciarlo
ollama serve

# Verificar conectividad
curl http://localhost:11434/api/tags
```

### **Error de dependencias:**
```bash
# Actualizar pip
pip install --upgrade pip

# Reinstalar dependencias
pip install --upgrade -r requirements.txt
```

### **Puerto ocupado:**
```bash
# Para la API (cambiar puerto)
python -m uvicorn src.app:app --reload --port 8001

# Actualizar en streamlit_app.py la lÃ­nea:
# API_URL = "http://localhost:8001/chat"
```

### **Modelo no encontrado:**
```bash
# Verificar modelos disponibles
ollama list

# Descargar modelo si no existe
ollama pull qwen3:8b

# Verificar que el nombre coincida en .env
# OLLAMA_MODEL=qwen3:8b
```

### **Error de conexiÃ³n en Streamlit:**
- Verificar que la API estÃ© corriendo en http://localhost:8000
- Revisar el indicador de estado en el sidebar de Streamlit
- Verificar logs en la terminal de la API

---

## ğŸ“ Estructura de archivos

```
langgraph/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py              # API FastAPI
â”‚   â”œâ”€â”€ graph.py            # Grafo LangGraph
â”‚   â”œâ”€â”€ llm.py              # Cliente LLM
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ system.md       # Prompt del sistema
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ weather.py      # Tool: clima
â”‚       â””â”€â”€ image.py        # Tool: imÃ¡genes
â”œâ”€â”€ static/generated/       # ImÃ¡genes generadas
â”œâ”€â”€ streamlit_app.py        # Interfaz Streamlit
â”œâ”€â”€ .env                    # Variables de entorno
â”œâ”€â”€ .env.example           # Ejemplo de configuraciÃ³n
â”œâ”€â”€ requirements.txt       # Dependencias
â””â”€â”€ guia_ejecucion.md     # Esta guÃ­a
```

---

## ğŸ¯ URLs importantes

- **API FastAPI:** http://localhost:8000
- **DocumentaciÃ³n API:** http://localhost:8000/docs
- **Interfaz Streamlit:** http://localhost:8501
- **Ollama API:** http://localhost:11434

---

## ğŸ›‘ Detener los servicios

```bash
# En cada terminal, presionar:
Ctrl + C

# Desactivar entorno virtual
deactivate
```

---

Â¡Listo! ğŸ‰ Tu bot multiagente deberÃ­a estar funcionando correctamente.